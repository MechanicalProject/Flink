2024-02-17 11:16:38,677 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2024-02-17 11:16:38,678 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Preconfiguration: 
2024-02-17 11:16:38,678 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - 


RESOURCE_PARAMS extraction logs:
jvm_params: -Xmx536870902 -Xms536870902 -XX:MaxDirectMemorySize=268435458 -XX:MaxMetaspaceSize=268435456
dynamic_configs: -D taskmanager.memory.network.min=134217730b -D taskmanager.cpu.cores=1.0 -D taskmanager.memory.task.off-heap.size=0b -D taskmanager.memory.jvm-metaspace.size=268435456b -D external-resources=none -D taskmanager.memory.jvm-overhead.min=201326592b -D taskmanager.memory.framework.off-heap.size=134217728b -D taskmanager.memory.network.max=134217730b -D taskmanager.memory.framework.heap.size=134217728b -D taskmanager.memory.managed.size=536870920b -D taskmanager.memory.task.heap.size=402653174b -D taskmanager.numberOfTaskSlots=1 -D taskmanager.memory.jvm-overhead.max=201326592b
logs: WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.
INFO  [] - Loading configuration property: taskmanager.memory.process.size, 1728m
INFO  [] - Loading configuration property: jobmanager.bind-host, localhost
INFO  [] - Loading configuration property: taskmanager.bind-host, localhost
INFO  [] - Loading configuration property: taskmanager.host, localhost
INFO  [] - Loading configuration property: parallelism.default, 1
INFO  [] - Loading configuration property: jobmanager.execution.failover-strategy, region
INFO  [] - Loading configuration property: jobmanager.rpc.address, localhost
INFO  [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
INFO  [] - Loading configuration property: rest.address, localhost
INFO  [] - Loading configuration property: jobmanager.memory.process.size, 1600m
INFO  [] - Loading configuration property: jobmanager.rpc.port, 6123
INFO  [] - Loading configuration property: rest.bind-address, localhost
INFO  [] - The derived from fraction jvm overhead memory (172.800mb (181193935 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
INFO  [] - Final TaskExecutor Memory configuration:
INFO  [] -   Total Process Memory:          1.688gb (1811939328 bytes)
INFO  [] -     Total Flink Memory:          1.250gb (1342177280 bytes)
INFO  [] -       Total JVM Heap Memory:     512.000mb (536870902 bytes)
INFO  [] -         Framework:               128.000mb (134217728 bytes)
INFO  [] -         Task:                    384.000mb (402653174 bytes)
INFO  [] -       Total Off-heap Memory:     768.000mb (805306378 bytes)
INFO  [] -         Managed:                 512.000mb (536870920 bytes)
INFO  [] -         Total JVM Direct Memory: 256.000mb (268435458 bytes)
INFO  [] -           Framework:             128.000mb (134217728 bytes)
INFO  [] -           Task:                  0 bytes
INFO  [] -           Network:               128.000mb (134217730 bytes)
INFO  [] -     JVM Metaspace:               256.000mb (268435456 bytes)
INFO  [] -     JVM Overhead:                192.000mb (201326592 bytes)

2024-02-17 11:16:38,678 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2024-02-17 11:16:38,678 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Starting TaskManager (Version: 1.17.0, Scala: 2.12, Rev:69ecda0, Date:2023-03-17T10:30:06+01:00)
2024-02-17 11:16:38,678 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  OS current user: jungeui
2024-02-17 11:16:38,678 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Current Hadoop/Kerberos user: <no hadoop dependency found>
2024-02-17 11:16:38,678 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JVM: OpenJDK 64-Bit Server VM - Azul Systems, Inc. - 11/11.0.21+9-LTS
2024-02-17 11:16:38,678 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Arch: aarch64
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Maximum heap size: 512 MiBytes
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JAVA_HOME: /Library/Java/JavaVirtualMachines/zulu-11.jdk/Contents/Home
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  No Hadoop Dependency available
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  JVM Options:
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:+UseG1GC
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Xmx536870902
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Xms536870902
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:MaxDirectMemorySize=268435458
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -XX:MaxMetaspaceSize=268435456
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog.file=/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/log/flink-jungeui-taskexecutor-0-findas-MacBook-Pro.local.log
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog4j.configuration=file:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/conf/log4j.properties
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlog4j.configurationFile=file:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/conf/log4j.properties
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -Dlogback.configurationFile=file:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/conf/logback.xml
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Program Arguments:
2024-02-17 11:16:38,679 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     --configDir
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     /Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/conf
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.network.min=134217730b
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.cpu.cores=1.0
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.task.off-heap.size=0b
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-metaspace.size=268435456b
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     external-resources=none
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-overhead.min=201326592b
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.framework.off-heap.size=134217728b
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.network.max=134217730b
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.framework.heap.size=134217728b
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.managed.size=536870920b
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.task.heap.size=402653174b
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.numberOfTaskSlots=1
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     -D
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -     taskmanager.memory.jvm-overhead.max=201326592b
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] -  Classpath: /Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-cep-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-connector-files-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-csv-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-json-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-scala_2.12-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-table-api-java-uber-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-table-planner-loader-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-table-runtime-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/log4j-1.2-api-2.17.1.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/log4j-api-2.17.1.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/log4j-core-2.17.1.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/log4j-slf4j-impl-2.17.1.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-dist-1.17.0.jar::::
2024-02-17 11:16:38,680 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - --------------------------------------------------------------------------------
2024-02-17 11:16:38,681 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2024-02-17 11:16:38,682 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Maximum number of open file descriptors is 10240.
2024-02-17 11:16:38,686 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1728m
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.bind-host, localhost
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.bind-host, localhost
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.host, localhost
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.address, localhost
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1600m
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.bind-address, localhost
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.network.min, 134217730b
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.jvm-metaspace.size, 268435456b
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.task.off-heap.size, 0b
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.cpu.cores, 1.0
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: external-resources, none
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.jvm-overhead.min, 201326592b
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.framework.off-heap.size, 134217728b
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.network.max, 134217730b
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.framework.heap.size, 134217728b
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.managed.size, 536870920b
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.task.heap.size, 402653174b
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.numberOfTaskSlots, 1
2024-02-17 11:16:38,687 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: taskmanager.memory.jvm-overhead.max, 201326592b
2024-02-17 11:16:38,710 INFO  org.apache.flink.core.fs.FileSystem                          [] - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2024-02-17 11:16:38,718 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-statsd
2024-02-17 11:16:38,721 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-prometheus
2024-02-17 11:16:38,721 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-graphite
2024-02-17 11:16:38,721 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: external-resource-gpu
2024-02-17 11:16:38,721 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-jmx
2024-02-17 11:16:38,721 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-influx
2024-02-17 11:16:38,721 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-slf4j
2024-02-17 11:16:38,721 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-datadog
2024-02-17 11:16:38,733 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - StateChangelogStorageLoader initialized with shortcut names {memory,filesystem}.
2024-02-17 11:16:38,733 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2024-02-17 11:16:38,733 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2024-02-17 11:16:38,733 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2024-02-17 11:16:38,733 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2024-02-17 11:16:38,733 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2024-02-17 11:16:38,733 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2024-02-17 11:16:38,734 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2024-02-17 11:16:38,734 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2024-02-17 11:16:38,735 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - StateChangelogStorageLoader initialized with shortcut names {memory,filesystem}.
2024-02-17 11:16:38,742 INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory [] - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.
2024-02-17 11:16:38,757 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/jaas-2968272544641900270.conf.
2024-02-17 11:16:38,761 INFO  org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory [] - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.
2024-02-17 11:16:38,969 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using configured hostname/address for TaskManager: localhost.
2024-02-17 11:16:38,993 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2024-02-17 11:16:39,358 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2024-02-17 11:16:39,374 INFO  akka.remote.RemoteActorRefProvider                           [] - Akka Cluster not in use - enabling unsafe features anyway because `akka.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2024-02-17 11:16:39,374 INFO  akka.remote.Remoting                                         [] - Starting remoting
2024-02-17 11:16:39,465 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@localhost:62155]
2024-02-17 11:16:39,519 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@localhost:62155
2024-02-17 11:16:39,528 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Using working directory: WorkingDirectory(/var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/tm_localhost:62155-ff2028)
2024-02-17 11:16:39,532 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2024-02-17 11:16:39,533 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2024-02-17 11:16:39,541 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2024-02-17 11:16:39,542 INFO  akka.remote.RemoteActorRefProvider                           [] - Akka Cluster not in use - enabling unsafe features anyway because `akka.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2024-02-17 11:16:39,542 INFO  akka.remote.Remoting                                         [] - Starting remoting
2024-02-17 11:16:39,547 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@localhost:62156]
2024-02-17 11:16:39,551 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@localhost:62156
2024-02-17 11:16:39,556 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService_localhost:62155-ff2028 .
2024-02-17 11:16:39,564 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Created BLOB cache storage directory /var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/tm_localhost:62155-ff2028/blobStorage
2024-02-17 11:16:39,566 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Created BLOB cache storage directory /var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/tm_localhost:62155-ff2028/blobStorage
2024-02-17 11:16:39,568 INFO  org.apache.flink.runtime.externalresource.ExternalResourceUtils [] - Enabled external resources: []
2024-02-17 11:16:39,568 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
2024-02-17 11:16:39,570 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
2024-02-17 11:16:39,570 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
2024-02-17 11:16:39,570 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2024-02-17 11:16:39,570 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2024-02-17 11:16:39,570 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2024-02-17 11:16:39,570 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2024-02-17 11:16:39,570 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2024-02-17 11:16:39,570 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2024-02-17 11:16:39,570 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2024-02-17 11:16:39,570 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2024-02-17 11:16:39,570 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
2024-02-17 11:16:39,571 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - Starting TaskManager with ResourceID: localhost:62155-ff2028
2024-02-17 11:16:39,582 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerServices    [] - Temporary file directory '/var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T': total 460 GB, usable 292 GB (63.48% usable)
2024-02-17 11:16:39,584 INFO  org.apache.flink.runtime.io.disk.iomanager.IOManager         [] - Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:
	/var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/flink-io-cae28123-7f22-4861-8d07-a5ef1cf83d89
2024-02-17 11:16:39,587 INFO  org.apache.flink.runtime.io.network.netty.NettyConfig        [] - NettyConfig [server address: localhost/127.0.0.1, server port: 0, ssl enabled: false, memory segment size (bytes): 32768, transport type: AUTO, number of server threads: 1 (manual), number of client threads: 1 (manual), server connect backlog: 0 (use Netty's default), client connect timeout (sec): 120, send/receive buffer size (bytes): 0 (use Netty's default)]
2024-02-17 11:16:39,616 INFO  org.apache.flink.runtime.io.network.NettyShuffleServiceFactory [] - Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:
	/var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/flink-netty-shuffle-b8a2e030-f5cb-418e-87de-b17e77f8acdf
2024-02-17 11:16:39,638 INFO  org.apache.flink.runtime.io.network.buffer.NetworkBufferPool [] - Allocated 128 MB for network buffer pool (number of memory segments: 4096, bytes per segment: 32768).
2024-02-17 11:16:39,644 INFO  org.apache.flink.runtime.io.network.NettyShuffleEnvironment  [] - Starting the network environment and its components.
2024-02-17 11:16:39,666 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Transport type 'auto': using NIO.
2024-02-17 11:16:39,667 INFO  org.apache.flink.runtime.io.network.netty.NettyClient        [] - Successful initialization (took 22 ms).
2024-02-17 11:16:39,669 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Transport type 'auto': using NIO.
2024-02-17 11:16:39,689 INFO  org.apache.flink.runtime.io.network.netty.NettyServer        [] - Successful initialization (took 21 ms). Listening on SocketAddress /127.0.0.1:62157.
2024-02-17 11:16:39,690 INFO  org.apache.flink.runtime.taskexecutor.KvStateService         [] - Starting the kvState service and its components.
2024-02-17 11:16:39,702 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
2024-02-17 11:16:39,710 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Start job leader service.
2024-02-17 11:16:39,712 INFO  org.apache.flink.runtime.filecache.FileCache                 [] - User file cache uses directory /var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/flink-dist-cache-09221c12-a325-4d78-ad79-0dafb2e92f6b
2024-02-17 11:16:39,713 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Connecting to ResourceManager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000).
2024-02-17 11:16:39,810 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Resolved ResourceManager address, beginning registration
2024-02-17 11:16:39,851 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Successful registration at resource manager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_* under registration id 292a6d635a695f2fe48e4dc0fa01d9f7.
2024-02-17 11:17:38,598 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request dc1fccc5ac9c6c9b114348edbae9d6e4 for job a3158e9d7bb148bbdd91cfe47f654d6e from resource manager with leader id 00000000000000000000000000000000.
2024-02-17 11:17:38,601 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for dc1fccc5ac9c6c9b114348edbae9d6e4.
2024-02-17 11:17:38,601 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job a3158e9d7bb148bbdd91cfe47f654d6e for job leader monitoring.
2024-02-17 11:17:38,602 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 with leader id 00000000-0000-0000-0000-000000000000.
2024-02-17 11:17:38,610 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2024-02-17 11:17:38,620 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job a3158e9d7bb148bbdd91cfe47f654d6e.
2024-02-17 11:17:38,620 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job a3158e9d7bb148bbdd91cfe47f654d6e.
2024-02-17 11:17:38,621 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job a3158e9d7bb148bbdd91cfe47f654d6e.
2024-02-17 11:17:38,637 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot dc1fccc5ac9c6c9b114348edbae9d6e4.
2024-02-17 11:17:38,645 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2024-02-17 11:17:38,649 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id a3158e9d7bb148bbdd91cfe47f654d6e
2024-02-17 11:17:38,652 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 (837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id dc1fccc5ac9c6c9b114348edbae9d6e4.
2024-02-17 11:17:38,653 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 (837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2024-02-17 11:17:38,654 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot dc1fccc5ac9c6c9b114348edbae9d6e4.
2024-02-17 11:17:38,654 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 (837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2024-02-17 11:17:38,659 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading a3158e9d7bb148bbdd91cfe47f654d6e/p-4540c33f6b2a5192f8b0fd78b0287b2c4f2112b5-9cda1ec695834ae15c65f3d1f7b71c0b from localhost/127.0.0.1:62152
2024-02-17 11:17:39,060 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@17bd8f28
2024-02-17 11:17:39,060 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2024-02-17 11:17:39,061 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2024-02-17 11:17:39,067 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 (837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-17 11:17:39,136 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 has no restore state.
2024-02-17 11:17:39,148 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-price-consumer-group-1
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = price-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-02-17 11:17:39,181 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2024-02-17 11:17:39,181 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2024-02-17 11:17:39,181 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1708136259180
2024-02-17 11:17:39,304 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-price-consumer-group-1, groupId=price-consumer-group] Cluster ID: 0lgNxGuOTou8OSP5mfUTsw
2024-02-17 11:17:39,306 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 will start reading the following 1 partitions from the committed group offsets in Kafka: [KafkaTopicPartition{topic='price', partition=0}]
2024-02-17 11:17:39,307 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 (837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2024-02-17 11:17:39,309 INFO  org.apache.flink.streaming.connectors.kafka.FlinkKafkaConsumerBase [] - Consumer subtask 0 creating fetcher with offsets {KafkaTopicPartition{topic='price', partition=0}=-915623761773}.
2024-02-17 11:17:39,312 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = consumer-price-consumer-group-2
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = true
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = price-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-02-17 11:17:39,315 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2024-02-17 11:17:39,315 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2024-02-17 11:17:39,315 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1708136259315
2024-02-17 11:17:39,318 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Subscribed to partition(s): price-0
2024-02-17 11:17:39,336 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Resetting the last seen epoch of partition price-0 to 0 since the associated topicId changed from null to Y25yZqMuRYywFXUbk-FbHw
2024-02-17 11:17:39,336 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Cluster ID: 0lgNxGuOTou8OSP5mfUTsw
2024-02-17 11:17:39,345 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Discovered group coordinator 127.0.0.1:29092 (id: 2147483646 rack: null)
2024-02-17 11:17:39,359 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Setting offset for partition price-0 to the committed offset FetchPosition{offset=49, offsetEpoch=Optional[0], currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:29092 (id: 1 rack: null)], epoch=0}}
2024-02-17 11:26:39,432 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Node -1 disconnected.
2024-02-17 12:55:13,721 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Disconnecting from node 1 due to request timeout.
2024-02-17 12:55:13,835 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Cancelled in-flight FETCH request with correlation id 12545 due to node 1 being disconnected (elapsed time since creation: 101179ms, elapsed time since send: 101179ms, request timeout: 30000ms)
2024-02-17 12:55:13,836 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Error sending fetch request (sessionId=243828376, epoch=11369) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2024-02-17 13:06:13,823 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Disconnecting from node 1 due to request timeout.
2024-02-17 13:06:13,824 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Cancelled in-flight FETCH request with correlation id 12576 due to node 1 being disconnected (elapsed time since creation: 647264ms, elapsed time since send: 647264ms, request timeout: 30000ms)
2024-02-17 13:06:13,825 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Error sending fetch request (sessionId=1078480910, epoch=25) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2024-02-17 13:07:04,762 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Disconnecting from node 1 due to request timeout.
2024-02-17 13:07:04,765 INFO  org.apache.kafka.clients.NetworkClient                       [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Cancelled in-flight FETCH request with correlation id 12602 due to node 1 being disconnected (elapsed time since creation: 40626ms, elapsed time since send: 40626ms, request timeout: 30000ms)
2024-02-17 13:07:04,765 INFO  org.apache.kafka.clients.FetchSessionHandler                 [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Error sending fetch request (sessionId=659896523, epoch=20) to node 1:
org.apache.kafka.common.errors.DisconnectException: null
2024-02-17 14:14:52,104 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Attempting to cancel task Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 (837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2024-02-17 14:14:52,106 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 (837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2024-02-17 14:14:52,106 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Triggering cancellation of task code Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 (837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2024-02-17 14:14:52,111 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-02-17 14:14:52,111 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-price-consumer-group-1, groupId=price-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-02-17 14:14:52,111 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-price-consumer-group-2, groupId=price-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2024-02-17 14:14:52,111 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=consumer-price-consumer-group-1, groupId=price-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2024-02-17 14:14:52,112 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2024-02-17 14:14:52,113 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2024-02-17 14:14:52,113 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-02-17 14:14:52,113 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-02-17 14:14:52,113 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2024-02-17 14:14:52,113 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2024-02-17 14:14:52,117 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for consumer-price-consumer-group-1 unregistered
2024-02-17 14:14:52,118 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for consumer-price-consumer-group-2 unregistered
2024-02-17 14:14:52,118 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 (837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2024-02-17 14:14:52,118 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 (837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2024-02-17 14:14:52,119 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state CANCELED to JobManager for task Source: Custom Source -> Sink: Print to Std. Out (1/1)#0 837c0de8aa87844edd28957d7e65c10d_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2024-02-17 14:14:52,156 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}, allocationId: dc1fccc5ac9c6c9b114348edbae9d6e4, jobId: a3158e9d7bb148bbdd91cfe47f654d6e).
2024-02-17 14:14:52,158 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job a3158e9d7bb148bbdd91cfe47f654d6e from job leader monitoring.
2024-02-17 14:14:52,158 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job a3158e9d7bb148bbdd91cfe47f654d6e.
2024-02-17 14:15:27,215 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Receive slot request 65bf6bd848d81cf87a854fe36606d422 for job f2d5ec2ddb82a9167f3f23d0bacb3bfe from resource manager with leader id 00000000000000000000000000000000.
2024-02-17 14:15:27,215 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Allocated slot for 65bf6bd848d81cf87a854fe36606d422.
2024-02-17 14:15:27,215 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Add job f2d5ec2ddb82a9167f3f23d0bacb3bfe for job leader monitoring.
2024-02-17 14:15:27,215 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Try to register at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_3 with leader id 00000000-0000-0000-0000-000000000000.
2024-02-17 14:15:27,218 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Resolved JobManager address, beginning registration
2024-02-17 14:15:27,221 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Successful registration at job manager akka.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job f2d5ec2ddb82a9167f3f23d0bacb3bfe.
2024-02-17 14:15:27,221 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Establish JobManager connection for job f2d5ec2ddb82a9167f3f23d0bacb3bfe.
2024-02-17 14:15:27,221 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Offer reserved slots to the leader of job f2d5ec2ddb82a9167f3f23d0bacb3bfe.
2024-02-17 14:15:27,224 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 65bf6bd848d81cf87a854fe36606d422.
2024-02-17 14:15:27,225 INFO  org.apache.flink.runtime.state.changelog.StateChangelogStorageLoader [] - Creating a changelog storage with name 'memory'.
2024-02-17 14:15:27,225 INFO  org.apache.flink.runtime.state.TaskExecutorChannelStateExecutorFactoryManager [] - Creating the channel state executor factory for job id f2d5ec2ddb82a9167f3f23d0bacb3bfe
2024-02-17 14:15:27,225 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Received task Source: Kafka Source -> Sink: Print to Std. Out (1/1)#0 (eb67127a575292995f4d57e94f28c95e_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 65bf6bd848d81cf87a854fe36606d422.
2024-02-17 14:15:27,225 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Activate slot 65bf6bd848d81cf87a854fe36606d422.
2024-02-17 14:15:27,225 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Print to Std. Out (1/1)#0 (eb67127a575292995f4d57e94f28c95e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
2024-02-17 14:15:27,226 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Loading JAR files for task Source: Kafka Source -> Sink: Print to Std. Out (1/1)#0 (eb67127a575292995f4d57e94f28c95e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
2024-02-17 14:15:27,226 INFO  org.apache.flink.runtime.blob.BlobClient                     [] - Downloading f2d5ec2ddb82a9167f3f23d0bacb3bfe/p-846f49dfe97930fa414cfc016689bed678a8636e-2aeb9032223640852be56647d949d062 from localhost/127.0.0.1:62152
2024-02-17 14:15:27,577 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@500f37c3
2024-02-17 14:15:27,577 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2024-02-17 14:15:27,577 INFO  org.apache.flink.streaming.runtime.tasks.StreamTask          [] - Checkpoint storage is set to 'jobmanager'
2024-02-17 14:15:27,577 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Print to Std. Out (1/1)#0 (eb67127a575292995f4d57e94f28c95e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-17 14:15:27,674 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Print to Std. Out (1/1)#0 (eb67127a575292995f4d57e94f28c95e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2024-02-17 14:15:27,679 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Adding split(s) to reader: [[Partition: price-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]
2024-02-17 14:15:27,689 INFO  org.apache.kafka.clients.consumer.ConsumerConfig             [] - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = latest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = price-consumer-group-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = price-consumer-group
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

2024-02-17 14:15:27,716 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'client.id.prefix' was supplied but isn't a known config.
2024-02-17 14:15:27,716 WARN  org.apache.kafka.clients.consumer.ConsumerConfig             [] - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2024-02-17 14:15:27,717 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2024-02-17 14:15:27,717 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2024-02-17 14:15:27,717 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1708146927716
2024-02-17 14:15:27,720 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Starting split fetcher 0
2024-02-17 14:15:27,722 INFO  org.apache.kafka.clients.consumer.KafkaConsumer              [] - [Consumer clientId=price-consumer-group-0, groupId=price-consumer-group] Subscribed to partition(s): price-0
2024-02-17 14:15:27,724 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=price-consumer-group-0, groupId=price-consumer-group] Seeking to LATEST offset of partition price-0
2024-02-17 14:15:27,825 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=price-consumer-group-0, groupId=price-consumer-group] Resetting the last seen epoch of partition price-0 to 0 since the associated topicId changed from null to Y25yZqMuRYywFXUbk-FbHw
2024-02-17 14:15:27,826 INFO  org.apache.kafka.clients.Metadata                            [] - [Consumer clientId=price-consumer-group-0, groupId=price-consumer-group] Cluster ID: 0lgNxGuOTou8OSP5mfUTsw
2024-02-17 14:15:27,855 INFO  org.apache.kafka.clients.consumer.internals.SubscriptionState [] - [Consumer clientId=price-consumer-group-0, groupId=price-consumer-group] Resetting offset for partition price-0 to position FetchPosition{offset=60, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[127.0.0.1:29092 (id: 1 rack: null)], epoch=0}}.
2024-02-17 14:16:10,339 INFO  org.apache.flink.connector.base.source.reader.SourceReaderBase [] - Closing Source Reader.
2024-02-17 14:16:10,339 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Shutting down split fetcher 0
2024-02-17 14:16:10,340 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=price-consumer-group-0, groupId=price-consumer-group] Resetting generation and member id due to: consumer pro-actively leaving the group
2024-02-17 14:16:10,340 INFO  org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [] - [Consumer clientId=price-consumer-group-0, groupId=price-consumer-group] Request joining group due to: consumer pro-actively leaving the group
2024-02-17 14:16:10,340 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2024-02-17 14:16:10,340 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-02-17 14:16:10,340 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2024-02-17 14:16:10,342 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.consumer for price-consumer-group-0 unregistered
2024-02-17 14:16:10,342 INFO  org.apache.flink.connector.base.source.reader.fetcher.SplitFetcher [] - Split fetcher 0 exited.
2024-02-17 14:16:10,342 WARN  org.apache.flink.runtime.taskmanager.Task                    [] - Source: Kafka Source -> Sink: Print to Std. Out (1/1)#0 (eb67127a575292995f4d57e94f28c95e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
java.io.IOException: Failed to deserialize consumer record due to
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:56) ~[blob_p-846f49dfe97930fa414cfc016689bed678a8636e-2aeb9032223640852be56647d949d062:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:33) ~[blob_p-846f49dfe97930fa414cfc016689bed678a8636e-2aeb9032223640852be56647d949d062:?]
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.pollNext(SourceReaderBase.java:144) ~[flink-connector-files-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.api.operators.SourceOperator.emitNext(SourceOperator.java:417) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamTaskSourceInput.emitNext(StreamTaskSourceInput.java:68) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) [flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) [flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) [flink-dist-1.17.0.jar:1.17.0]
	at java.lang.Thread.run(Thread.java:829) [?:?]
Caused by: org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException: Unrecognized field "data" (class schema.Price), not marked as ignorable (2 known properties: "Data", "timestamp"])
 at [Source: (byte[])"{"data": [{"symbol": "ETHBTC", "price": "0.05368000"}, {"symbol": "XRPBTC", "price": "0.00001076"}, {"symbol": "ADABTC", "price": "0.00001135"}, {"symbol": "BTCUSDC", "price": "51932.40000000"}], "timestamp": "2024-02-17T05:16:10"}"; line: 1, column: 11] (through reference chain: schema.Price["data"])
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.exc.UnrecognizedPropertyException.from(UnrecognizedPropertyException.java:61) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.DeserializationContext.handleUnknownProperty(DeserializationContext.java:1127) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.std.StdDeserializer.handleUnknownProperty(StdDeserializer.java:2023) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownProperty(BeanDeserializerBase.java:1700) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.BeanDeserializerBase.handleUnknownVanilla(BeanDeserializerBase.java:1678) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.BeanDeserializer.vanillaDeserialize(BeanDeserializer.java:320) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.BeanDeserializer.deserialize(BeanDeserializer.java:177) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.deser.DefaultDeserializationContext.readRootValue(DefaultDeserializationContext.java:323) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper._readMapAndClose(ObjectMapper.java:4674) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.shaded.jackson2.com.fasterxml.jackson.databind.ObjectMapper.readValue(ObjectMapper.java:3690) ~[flink-dist-1.17.0.jar:1.17.0]
	at schema.KafkaPriceSchema.deserialize(KafkaPriceSchema.java:21) ~[blob_p-846f49dfe97930fa414cfc016689bed678a8636e-2aeb9032223640852be56647d949d062:?]
	at schema.KafkaPriceSchema.deserialize(KafkaPriceSchema.java:8) ~[blob_p-846f49dfe97930fa414cfc016689bed678a8636e-2aeb9032223640852be56647d949d062:?]
	at org.apache.flink.api.common.serialization.DeserializationSchema.deserialize(DeserializationSchema.java:82) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.connector.kafka.source.reader.deserializer.KafkaValueOnlyDeserializationSchemaWrapper.deserialize(KafkaValueOnlyDeserializationSchemaWrapper.java:51) ~[blob_p-846f49dfe97930fa414cfc016689bed678a8636e-2aeb9032223640852be56647d949d062:?]
	at org.apache.flink.connector.kafka.source.reader.KafkaRecordEmitter.emitRecord(KafkaRecordEmitter.java:53) ~[blob_p-846f49dfe97930fa414cfc016689bed678a8636e-2aeb9032223640852be56647d949d062:?]
	... 14 more
2024-02-17 14:16:10,345 INFO  org.apache.flink.runtime.taskmanager.Task                    [] - Freeing task resources for Source: Kafka Source -> Sink: Print to Std. Out (1/1)#0 (eb67127a575292995f4d57e94f28c95e_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
2024-02-17 14:16:10,350 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Un-registering task and sending final execution state FAILED to JobManager for task Source: Kafka Source -> Sink: Print to Std. Out (1/1)#0 eb67127a575292995f4d57e94f28c95e_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
2024-02-17 14:16:10,381 INFO  org.apache.flink.runtime.taskexecutor.slot.TaskSlotTableImpl [] - Free slot TaskSlot(index:0, state:ACTIVE, resource profile: ResourceProfile{cpuCores=1, taskHeapMemory=384.000mb (402653174 bytes), taskOffHeapMemory=0 bytes, managedMemory=512.000mb (536870920 bytes), networkMemory=128.000mb (134217730 bytes)}, allocationId: 65bf6bd848d81cf87a854fe36606d422, jobId: f2d5ec2ddb82a9167f3f23d0bacb3bfe).
2024-02-17 14:16:10,382 INFO  org.apache.flink.runtime.taskexecutor.DefaultJobLeaderService [] - Remove job f2d5ec2ddb82a9167f3f23d0bacb3bfe from job leader monitoring.
2024-02-17 14:16:10,382 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close JobManager connection for job f2d5ec2ddb82a9167f3f23d0bacb3bfe.
2024-02-17 14:20:54,628 INFO  org.apache.flink.runtime.taskexecutor.TaskManagerRunner      [] - RECEIVED SIGNAL 15: SIGTERM. Shutting down as requested.
2024-02-17 14:20:54,629 INFO  org.apache.flink.runtime.state.TaskExecutorStateChangelogStoragesManager [] - Shutting down TaskExecutorStateChangelogStoragesManager.
2024-02-17 14:20:54,629 INFO  org.apache.flink.runtime.blob.PermanentBlobCache             [] - Shutting down BLOB cache
2024-02-17 14:20:54,629 INFO  org.apache.flink.runtime.blob.TransientBlobCache             [] - Shutting down BLOB cache
2024-02-17 14:20:54,630 INFO  org.apache.flink.runtime.state.TaskExecutorLocalStateStoresManager [] - Shutting down TaskExecutorLocalStateStoresManager.
2024-02-17 14:20:54,631 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Stopping TaskExecutor akka.tcp://flink@localhost:62155/user/rpc/taskmanager_0.
2024-02-17 14:20:54,631 INFO  org.apache.flink.runtime.taskexecutor.TaskExecutor           [] - Close ResourceManager connection 82f05dbdf213099ccf058da693fc25a7.
