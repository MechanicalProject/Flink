2024-02-19 13:50:56,550 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Preconfiguration: 
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - 


RESOURCE_PARAMS extraction logs:
jvm_params: -Xmx1073741824 -Xms1073741824 -XX:MaxMetaspaceSize=268435456
dynamic_configs: -D jobmanager.memory.off-heap.size=134217728b -D jobmanager.memory.jvm-overhead.min=201326592b -D jobmanager.memory.jvm-metaspace.size=268435456b -D jobmanager.memory.heap.size=1073741824b -D jobmanager.memory.jvm-overhead.max=201326592b
logs: WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.
INFO  [] - Loading configuration property: taskmanager.memory.process.size, 1728m
INFO  [] - Loading configuration property: jobmanager.bind-host, localhost
INFO  [] - Loading configuration property: taskmanager.bind-host, localhost
INFO  [] - Loading configuration property: taskmanager.host, localhost
INFO  [] - Loading configuration property: parallelism.default, 1
INFO  [] - Loading configuration property: jobmanager.execution.failover-strategy, region
INFO  [] - Loading configuration property: jobmanager.rpc.address, localhost
INFO  [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
INFO  [] - Loading configuration property: rest.address, localhost
INFO  [] - Loading configuration property: jobmanager.memory.process.size, 1600m
INFO  [] - Loading configuration property: jobmanager.rpc.port, 6123
INFO  [] - Loading configuration property: rest.bind-address, localhost
INFO  [] - The derived from fraction jvm overhead memory (160.000mb (167772162 bytes)) is less than its min value 192.000mb (201326592 bytes), min value will be used instead
INFO  [] - Final Master Memory configuration:
INFO  [] -   Total Process Memory: 1.563gb (1677721600 bytes)
INFO  [] -     Total Flink Memory: 1.125gb (1207959552 bytes)
INFO  [] -       JVM Heap:         1024.000mb (1073741824 bytes)
INFO  [] -       Off-heap:         128.000mb (134217728 bytes)
INFO  [] -     JVM Metaspace:      256.000mb (268435456 bytes)
INFO  [] -     JVM Overhead:       192.000mb (201326592 bytes)

2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Starting StandaloneSessionClusterEntrypoint (Version: 1.17.0, Scala: 2.12, Rev:69ecda0, Date:2023-03-17T10:30:06+01:00)
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  OS current user: jungeui
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Current Hadoop/Kerberos user: <no hadoop dependency found>
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM: OpenJDK 64-Bit Server VM - Azul Systems, Inc. - 11/11.0.21+9-LTS
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Arch: aarch64
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Maximum heap size: 1024 MiBytes
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JAVA_HOME: /Library/Java/JavaVirtualMachines/zulu-11.jdk/Contents/Home
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  No Hadoop Dependency available
2024-02-19 13:50:56,551 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  JVM Options:
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xmx1073741824
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Xms1073741824
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -XX:MaxMetaspaceSize=268435456
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog.file=/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/log/flink-jungeui-standalonesession-0-findas-MacBook-Pro.local.log
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configuration=file:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/conf/log4j.properties
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlog4j.configurationFile=file:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/conf/log4j.properties
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -Dlogback.configurationFile=file:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/conf/logback.xml
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Program Arguments:
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.off-heap.size=134217728b
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-overhead.min=201326592b
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-metaspace.size=268435456b
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.heap.size=1073741824b
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     -D
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     jobmanager.memory.jvm-overhead.max=201326592b
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --configDir
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     /Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/conf
2024-02-19 13:50:56,552 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     --executionMode
2024-02-19 13:50:56,553 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -     cluster
2024-02-19 13:50:56,553 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] -  Classpath: /Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-cep-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-connector-files-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-csv-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-json-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-scala_2.12-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-table-api-java-uber-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-table-planner-loader-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-table-runtime-1.17.0.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/log4j-1.2-api-2.17.1.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/log4j-api-2.17.1.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/log4j-core-2.17.1.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/log4j-slf4j-impl-2.17.1.jar:/Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/lib/flink-dist-1.17.0.jar::::
2024-02-19 13:50:56,553 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - --------------------------------------------------------------------------------
2024-02-19 13:50:56,553 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Registered UNIX signal handlers for [TERM, HUP, INT]
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.memory.process.size, 1728m
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.bind-host, localhost
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.bind-host, localhost
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.host, localhost
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: parallelism.default, 1
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.execution.failover-strategy, region
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.address, localhost
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: taskmanager.numberOfTaskSlots, 1
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.address, localhost
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.memory.process.size, 1600m
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: jobmanager.rpc.port, 6123
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading configuration property: rest.bind-address, localhost
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.off-heap.size, 134217728b
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-overhead.min, 201326592b
2024-02-19 13:50:56,560 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-metaspace.size, 268435456b
2024-02-19 13:50:56,561 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.heap.size, 1073741824b
2024-02-19 13:50:56,561 INFO  org.apache.flink.configuration.GlobalConfiguration           [] - Loading dynamic configuration property: jobmanager.memory.jvm-overhead.max, 201326592b
2024-02-19 13:50:56,575 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Starting StandaloneSessionClusterEntrypoint.
2024-02-19 13:50:56,596 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install default filesystem.
2024-02-19 13:50:56,599 INFO  org.apache.flink.core.fs.FileSystem                          [] - Hadoop is not in the classpath/dependencies. The extended set of supported File Systems via Hadoop is not available.
2024-02-19 13:50:56,608 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-statsd
2024-02-19 13:50:56,611 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-prometheus
2024-02-19 13:50:56,611 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-graphite
2024-02-19 13:50:56,611 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: external-resource-gpu
2024-02-19 13:50:56,612 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-jmx
2024-02-19 13:50:56,612 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-influx
2024-02-19 13:50:56,612 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-slf4j
2024-02-19 13:50:56,612 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID not found, creating it: metrics-datadog
2024-02-19 13:50:56,626 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Install security context.
2024-02-19 13:50:56,636 INFO  org.apache.flink.runtime.security.modules.HadoopModuleFactory [] - Cannot create Hadoop Security Module because Hadoop cannot be found in the Classpath.
2024-02-19 13:50:56,648 INFO  org.apache.flink.runtime.security.modules.JaasModule         [] - Jaas file will be created as /var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/jaas-17140035651013786210.conf.
2024-02-19 13:50:56,653 INFO  org.apache.flink.runtime.security.contexts.HadoopSecurityContextFactory [] - Cannot install HadoopSecurityContext because Hadoop cannot be found in the Classpath.
2024-02-19 13:50:56,654 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Initializing cluster services.
2024-02-19 13:50:56,659 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Using working directory: WorkingDirectory(/var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/jm_0e97d5ff2a0642a0362e4fa920c6027b).
2024-02-19 13:50:56,884 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address localhost:6123, bind address localhost:6123.
2024-02-19 13:50:57,253 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2024-02-19 13:50:57,265 INFO  akka.remote.RemoteActorRefProvider                           [] - Akka Cluster not in use - enabling unsafe features anyway because `akka.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2024-02-19 13:50:57,265 INFO  akka.remote.Remoting                                         [] - Starting remoting
2024-02-19 13:50:57,352 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink@localhost:6123]
2024-02-19 13:50:57,404 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink@localhost:6123
2024-02-19 13:50:57,419 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Created BLOB server storage directory /var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/jm_0e97d5ff2a0642a0362e4fa920c6027b/blobStorage
2024-02-19 13:50:57,421 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Started BLOB server at 127.0.0.1:59696 - max concurrent requests: 50 - max backlog: 1000
2024-02-19 13:50:57,424 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Loading delegation token providers
2024-02-19 13:50:57,426 INFO  org.apache.flink.runtime.security.token.hadoop.HadoopFSDelegationTokenProvider [] - Hadoop FS is not available (not packaged with this application): NoClassDefFoundError : "org/apache/hadoop/conf/Configuration".
2024-02-19 13:50:57,426 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hadoopfs loaded and initialized
2024-02-19 13:50:57,426 INFO  org.apache.flink.runtime.security.token.hadoop.HBaseDelegationTokenProvider [] - HBase is not available (not packaged with this application): NoClassDefFoundError : "org/apache/hadoop/conf/Configuration".
2024-02-19 13:50:57,426 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token provider hbase loaded and initialized
2024-02-19 13:50:57,426 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2024-02-19 13:50:57,426 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2024-02-19 13:50:57,426 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2024-02-19 13:50:57,426 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2024-02-19 13:50:57,426 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2024-02-19 13:50:57,426 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2024-02-19 13:50:57,427 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2024-02-19 13:50:57,427 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2024-02-19 13:50:57,427 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Delegation token providers loaded successfully
2024-02-19 13:50:57,428 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Loading delegation token receivers
2024-02-19 13:50:57,429 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hadoopfs loaded and initialized
2024-02-19 13:50:57,429 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receiver hbase loaded and initialized
2024-02-19 13:50:57,429 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-statsd
2024-02-19 13:50:57,429 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-prometheus
2024-02-19 13:50:57,429 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-graphite
2024-02-19 13:50:57,429 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: external-resource-gpu
2024-02-19 13:50:57,429 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-jmx
2024-02-19 13:50:57,429 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-influx
2024-02-19 13:50:57,429 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-slf4j
2024-02-19 13:50:57,429 INFO  org.apache.flink.core.plugin.DefaultPluginManager            [] - Plugin loader with ID found, reusing it: metrics-datadog
2024-02-19 13:50:57,429 INFO  org.apache.flink.runtime.security.token.DelegationTokenReceiverRepository [] - Delegation token receivers loaded successfully
2024-02-19 13:50:57,429 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Checking provider and receiver instances consistency
2024-02-19 13:50:57,429 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Provider and receiver instances are consistent
2024-02-19 13:50:57,434 INFO  org.apache.flink.runtime.metrics.MetricRegistryImpl          [] - No metrics reporter configured, no metrics will be exposed/reported.
2024-02-19 13:50:57,437 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Trying to start actor system, external address localhost:0, bind address localhost:0.
2024-02-19 13:50:57,444 INFO  akka.event.slf4j.Slf4jLogger                                 [] - Slf4jLogger started
2024-02-19 13:50:57,446 INFO  akka.remote.RemoteActorRefProvider                           [] - Akka Cluster not in use - enabling unsafe features anyway because `akka.remote.use-unsafe-remote-features-outside-cluster` has been enabled.
2024-02-19 13:50:57,446 INFO  akka.remote.Remoting                                         [] - Starting remoting
2024-02-19 13:50:57,450 INFO  akka.remote.Remoting                                         [] - Remoting started; listening on addresses :[akka.tcp://flink-metrics@localhost:59697]
2024-02-19 13:50:57,454 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcServiceUtils        [] - Actor system started at akka.tcp://flink-metrics@localhost:59697
2024-02-19 13:50:57,460 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
2024-02-19 13:50:57,471 INFO  org.apache.flink.runtime.dispatcher.FileExecutionGraphInfoStore [] - Initializing FileExecutionGraphInfoStore: Storage directory /var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/executionGraphStore-c4721106-ea01-4b1d-8bf9-78f8ca3c4ecb, expiration time 3600000, maximum cache size 52428800 bytes.
2024-02-19 13:50:57,508 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Upload directory /var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/flink-web-5c823592-7356-4dec-8883-4d4f9a6e50d5/flink-web-upload does not exist. 
2024-02-19 13:50:57,509 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Created directory /var/folders/yq/hx95c8bd3zn9mqv34g3gxbfc0000gp/T/flink-web-5c823592-7356-4dec-8883-4d4f9a6e50d5/flink-web-upload for file uploads.
2024-02-19 13:50:57,511 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Starting rest endpoint.
2024-02-19 13:50:57,649 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component log file: /Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/log/flink-jungeui-standalonesession-0-findas-MacBook-Pro.local.log
2024-02-19 13:50:57,650 INFO  org.apache.flink.runtime.webmonitor.WebMonitorUtils          [] - Determined location of main cluster component stdout file: /Users/jungeui/Documents/workspace/Flink-Study/flink-1.17.0/log/flink-jungeui-standalonesession-0-findas-MacBook-Pro.local.out
2024-02-19 13:50:57,704 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Rest endpoint listening at 127.0.0.1:8081
2024-02-19 13:50:57,706 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - http://127.0.0.1:8081 was granted leadership with leaderSessionID=00000000-0000-0000-0000-000000000000
2024-02-19 13:50:57,706 INFO  org.apache.flink.runtime.dispatcher.DispatcherRestEndpoint   [] - Web frontend listening at http://127.0.0.1:8081.
2024-02-19 13:50:57,716 INFO  org.apache.flink.runtime.dispatcher.runner.DefaultDispatcherRunner [] - DefaultDispatcherRunner was granted leadership with leader id 00000000-0000-0000-0000-000000000000. Creating new DispatcherLeaderProcess.
2024-02-19 13:50:57,718 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Start SessionDispatcherLeaderProcess.
2024-02-19 13:50:57,719 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Starting resource manager service.
2024-02-19 13:50:57,719 INFO  org.apache.flink.runtime.resourcemanager.ResourceManagerServiceImpl [] - Resource manager service is granted leadership with session id 00000000-0000-0000-0000-000000000000.
2024-02-19 13:50:57,720 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Recover all persisted job graphs that are not finished, yet.
2024-02-19 13:50:57,720 INFO  org.apache.flink.runtime.dispatcher.runner.SessionDispatcherLeaderProcess [] - Successfully recovered 0 persisted job graphs.
2024-02-19 13:50:57,728 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_0 .
2024-02-19 13:50:57,730 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
2024-02-19 13:50:57,735 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Starting the resource manager.
2024-02-19 13:50:57,740 INFO  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Starting tokens update task
2024-02-19 13:50:57,741 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - No tokens obtained so skipping listener notification
2024-02-19 13:50:57,741 WARN  org.apache.flink.runtime.security.token.DefaultDelegationTokenManager [] - Tokens update task not started because either no tokens obtained or none of the tokens specified its renewal date
2024-02-19 13:51:03,413 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering TaskManager with ResourceID localhost:59700-9f4b30 (akka.tcp://flink@localhost:59700/user/rpc/taskmanager_0) at ResourceManager
2024-02-19 14:52:31,299 WARN  org.apache.flink.runtime.webmonitor.handlers.JarRunHandler   [] - Configuring the job submission via query parameters is deprecated. Please migrate to submitting a JSON request instead.
2024-02-19 14:52:31,336 INFO  org.apache.flink.client.ClientUtils                          [] - Starting program (detached: true)
2024-02-19 14:52:31,383 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Field Price#data will be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-02-19 14:52:31,476 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Job 6bc50ecae98efcf1838aef1b3e5c0c50 is submitted.
2024-02-19 14:52:31,476 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Submitting Job with JobId=6bc50ecae98efcf1838aef1b3e5c0c50.
2024-02-19 14:52:31,854 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'Run Price Consumer' (6bc50ecae98efcf1838aef1b3e5c0c50).
2024-02-19 14:52:31,855 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'Run Price Consumer' (6bc50ecae98efcf1838aef1b3e5c0c50).
2024-02-19 14:52:31,866 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_2 .
2024-02-19 14:52:31,870 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'Run Price Consumer' (6bc50ecae98efcf1838aef1b3e5c0c50).
2024-02-19 14:52:31,882 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for Run Price Consumer (6bc50ecae98efcf1838aef1b3e5c0c50).
2024-02-19 14:52:31,897 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph ee44123b4e836a34aceb43290032a164 for job 6bc50ecae98efcf1838aef1b3e5c0c50.
2024-02-19 14:52:31,905 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job Run Price Consumer (6bc50ecae98efcf1838aef1b3e5c0c50).
2024-02-19 14:52:31,905 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2024-02-19 14:52:31,934 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 1 ms, total 1 pipelined regions currently.
2024-02-19 14:52:31,941 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3b596abb
2024-02-19 14:52:31,941 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2024-02-19 14:52:31,942 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2024-02-19 14:52:31,957 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-02-19 14:52:31,960 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@2e7e1c5a for Run Price Consumer (6bc50ecae98efcf1838aef1b3e5c0c50).
2024-02-19 14:52:31,965 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'Run Price Consumer' (6bc50ecae98efcf1838aef1b3e5c0c50) under job master id 00000000000000000000000000000000.
2024-02-19 14:52:31,967 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Kafka Source.
2024-02-19 14:52:31,969 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2024-02-19 14:52:31,969 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (6bc50ecae98efcf1838aef1b3e5c0c50) switched from state CREATED to RUNNING.
2024-02-19 14:52:31,970 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (ee44123b4e836a34aceb43290032a164_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2024-02-19 14:52:31,971 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (ee44123b4e836a34aceb43290032a164_90bea66de1c231edf33913ecd54406c1_0_0) switched from CREATED to SCHEDULED.
2024-02-19 14:52:31,977 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = price-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-02-19 14:52:31,978 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2024-02-19 14:52:31,979 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2024-02-19 14:52:31,980 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 6bc50ecae98efcf1838aef1b3e5c0c50.
2024-02-19 14:52:31,984 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 6bc50ecae98efcf1838aef1b3e5c0c50.
2024-02-19 14:52:31,984 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2024-02-19 14:52:31,986 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job 6bc50ecae98efcf1838aef1b3e5c0c50: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-02-19 14:52:32,005 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2024-02-19 14:52:32,005 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2024-02-19 14:52:32,005 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2024-02-19 14:52:32,005 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'client.id.prefix' was supplied but isn't a known config.
2024-02-19 14:52:32,005 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2024-02-19 14:52:32,005 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2024-02-19 14:52:32,005 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2024-02-19 14:52:32,005 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2024-02-19 14:52:32,005 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2024-02-19 14:52:32,005 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1708321952005
2024-02-19 14:52:32,006 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group price-consumer-group without periodic partition discovery.
2024-02-19 14:52:32,080 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (ee44123b4e836a34aceb43290032a164_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2024-02-19 14:52:32,081 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Flat Map (1/1) (attempt #0) with attempt id ee44123b4e836a34aceb43290032a164_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:59700-9f4b30 @ localhost (dataPort=59702) with allocation id b53c409abaa8be6513fcc0bc7f0efac0
2024-02-19 14:52:32,084 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (ee44123b4e836a34aceb43290032a164_90bea66de1c231edf33913ecd54406c1_0_0) switched from SCHEDULED to DEPLOYING.
2024-02-19 14:52:32,084 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying KeyedProcess -> Sink: Unnamed (1/1) (attempt #0) with attempt id ee44123b4e836a34aceb43290032a164_90bea66de1c231edf33913ecd54406c1_0_0 and vertex id 90bea66de1c231edf33913ecd54406c1_0 to localhost:59700-9f4b30 @ localhost (dataPort=59702) with allocation id b53c409abaa8be6513fcc0bc7f0efac0
2024-02-19 14:52:32,147 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [price-0]
2024-02-19 14:52:32,542 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (ee44123b4e836a34aceb43290032a164_90bea66de1c231edf33913ecd54406c1_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-19 14:52:32,543 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (ee44123b4e836a34aceb43290032a164_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-19 14:52:32,621 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (ee44123b4e836a34aceb43290032a164_90bea66de1c231edf33913ecd54406c1_0_0) switched from INITIALIZING to RUNNING.
2024-02-19 14:52:32,655 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (ee44123b4e836a34aceb43290032a164_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2024-02-19 14:52:32,655 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 0 (#0) @ localhost
2024-02-19 14:52:32,656 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: price-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]}
2024-02-19 14:52:47,995 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (ee44123b4e836a34aceb43290032a164_90bea66de1c231edf33913ecd54406c1_0_0) switched from RUNNING to FAILED on localhost:59700-9f4b30 @ localhost (dataPort=59702).
java.lang.IndexOutOfBoundsException: Index: 2, Size: 2
	at java.util.LinkedList.checkElementIndex(LinkedList.java:559) ~[?:?]
	at java.util.LinkedList.get(LinkedList.java:480) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:96) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62) ~[?:?]
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
2024-02-19 14:52:48,009 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (6bc50ecae98efcf1838aef1b3e5c0c50) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:258) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:249) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:242) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:748) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:725) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:80) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:479) ~[flink-dist-1.17.0.jar:1.17.0]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:309) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:307) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:222) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive(Actor.scala:537) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive$(Actor.scala:535) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.invoke(ActorCell.scala:547) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.run(Mailbox.scala:231) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290) [?:?]
	at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) [?:?]
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) [?:?]
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) [?:?]
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) [?:?]
Caused by: java.lang.IndexOutOfBoundsException: Index: 2, Size: 2
	at java.util.LinkedList.checkElementIndex(LinkedList.java:559) ~[?:?]
	at java.util.LinkedList.get(LinkedList.java:480) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:96) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62) ~[?:?]
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
2024-02-19 14:52:48,013 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (ee44123b4e836a34aceb43290032a164_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2024-02-19 14:52:48,030 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (ee44123b4e836a34aceb43290032a164_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2024-02-19 14:52:48,032 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Clearing resource requirements of job 6bc50ecae98efcf1838aef1b3e5c0c50
2024-02-19 14:52:48,031 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (6bc50ecae98efcf1838aef1b3e5c0c50) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:258) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:249) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:242) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:748) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:725) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:80) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:479) ~[flink-dist-1.17.0.jar:1.17.0]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:309) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:307) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:222) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive(Actor.scala:537) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive$(Actor.scala:535) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.invoke(ActorCell.scala:547) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.run(Mailbox.scala:231) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290) [?:?]
	at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) [?:?]
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) [?:?]
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) [?:?]
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) [?:?]
Caused by: java.lang.IndexOutOfBoundsException: Index: 2, Size: 2
	at java.util.LinkedList.checkElementIndex(LinkedList.java:559) ~[?:?]
	at java.util.LinkedList.get(LinkedList.java:480) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:96) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62) ~[?:?]
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
2024-02-19 14:52:48,032 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 6bc50ecae98efcf1838aef1b3e5c0c50.
2024-02-19 14:52:48,036 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 6bc50ecae98efcf1838aef1b3e5c0c50 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:83)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:258)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:249)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:242)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:748)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:725)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:80)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:479)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:309)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:307)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:222)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.IndexOutOfBoundsException: Index: 2, Size: 2
	at java.base/java.util.LinkedList.checkElementIndex(LinkedList.java:559)
	at java.base/java.util.LinkedList.get(LinkedList.java:480)
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:96)
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62)
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83)
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237)
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146)
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
2024-02-19 14:52:48,048 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 6bc50ecae98efcf1838aef1b3e5c0c50 has been registered for cleanup in the JobResultStore after reaching a terminal state.
2024-02-19 14:52:48,049 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'Run Price Consumer' (6bc50ecae98efcf1838aef1b3e5c0c50).
2024-02-19 14:52:48,051 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Kafka Source.
2024-02-19 14:52:48,052 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2024-02-19 14:52:48,052 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for price-consumer-group-enumerator-admin-client unregistered
2024-02-19 14:52:48,052 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:59700-9f4b30 because: Stopping JobMaster for job 'Run Price Consumer' (6bc50ecae98efcf1838aef1b3e5c0c50).
2024-02-19 14:52:48,053 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [b53c409abaa8be6513fcc0bc7f0efac0].
2024-02-19 14:52:48,053 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 0e97d5ff2a0642a0362e4fa920c6027b: Stopping JobMaster for job 'Run Price Consumer' (6bc50ecae98efcf1838aef1b3e5c0c50).
2024-02-19 14:52:48,054 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_2 for job 6bc50ecae98efcf1838aef1b3e5c0c50 from the resource manager.
2024-02-19 14:52:48,055 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2024-02-19 14:52:48,055 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-02-19 14:52:48,055 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2024-02-19 14:52:48,055 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Kafka Source closed.
2024-02-19 15:03:11,022 WARN  org.apache.flink.runtime.webmonitor.handlers.JarRunHandler   [] - Configuring the job submission via query parameters is deprecated. Please migrate to submitting a JSON request instead.
2024-02-19 15:03:11,072 INFO  org.apache.flink.client.ClientUtils                          [] - Starting program (detached: true)
2024-02-19 15:03:11,086 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Field Price#data will be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-02-19 15:03:11,107 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Job e684f68e53cc2501fe399a981490fe4b is submitted.
2024-02-19 15:03:11,108 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Submitting Job with JobId=e684f68e53cc2501fe399a981490fe4b.
2024-02-19 15:03:11,457 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'Run Price Consumer' (e684f68e53cc2501fe399a981490fe4b).
2024-02-19 15:03:11,458 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'Run Price Consumer' (e684f68e53cc2501fe399a981490fe4b).
2024-02-19 15:03:11,458 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
2024-02-19 15:03:11,459 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'Run Price Consumer' (e684f68e53cc2501fe399a981490fe4b).
2024-02-19 15:03:11,460 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for Run Price Consumer (e684f68e53cc2501fe399a981490fe4b).
2024-02-19 15:03:11,460 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 1da3547ae8fff4202794575a02f9f6a8 for job e684f68e53cc2501fe399a981490fe4b.
2024-02-19 15:03:11,460 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job Run Price Consumer (e684f68e53cc2501fe399a981490fe4b).
2024-02-19 15:03:11,460 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2024-02-19 15:03:11,471 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2024-02-19 15:03:11,471 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@780ec8d7
2024-02-19 15:03:11,471 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2024-02-19 15:03:11,471 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2024-02-19 15:03:11,472 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-02-19 15:03:11,472 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@63470961 for Run Price Consumer (e684f68e53cc2501fe399a981490fe4b).
2024-02-19 15:03:11,472 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'Run Price Consumer' (e684f68e53cc2501fe399a981490fe4b) under job master id 00000000000000000000000000000000.
2024-02-19 15:03:11,472 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Kafka Source.
2024-02-19 15:03:11,474 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2024-02-19 15:03:11,474 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (e684f68e53cc2501fe399a981490fe4b) switched from state CREATED to RUNNING.
2024-02-19 15:03:11,475 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1da3547ae8fff4202794575a02f9f6a8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2024-02-19 15:03:11,475 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (1da3547ae8fff4202794575a02f9f6a8_90bea66de1c231edf33913ecd54406c1_0_0) switched from CREATED to SCHEDULED.
2024-02-19 15:03:11,475 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2024-02-19 15:03:11,475 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2024-02-19 15:03:11,476 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job e684f68e53cc2501fe399a981490fe4b.
2024-02-19 15:03:11,476 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job e684f68e53cc2501fe399a981490fe4b.
2024-02-19 15:03:11,476 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2024-02-19 15:03:11,476 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job e684f68e53cc2501fe399a981490fe4b: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-02-19 15:03:11,480 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = price-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-02-19 15:03:11,499 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2024-02-19 15:03:11,499 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2024-02-19 15:03:11,499 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2024-02-19 15:03:11,499 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'client.id.prefix' was supplied but isn't a known config.
2024-02-19 15:03:11,499 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2024-02-19 15:03:11,499 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2024-02-19 15:03:11,499 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2024-02-19 15:03:11,499 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2024-02-19 15:03:11,500 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2024-02-19 15:03:11,500 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1708322591499
2024-02-19 15:03:11,500 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group price-consumer-group without periodic partition discovery.
2024-02-19 15:03:11,545 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1da3547ae8fff4202794575a02f9f6a8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2024-02-19 15:03:11,546 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Flat Map (1/1) (attempt #0) with attempt id 1da3547ae8fff4202794575a02f9f6a8_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:59700-9f4b30 @ localhost (dataPort=59702) with allocation id 8b297cd103e340ade795beb618768c04
2024-02-19 15:03:11,546 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (1da3547ae8fff4202794575a02f9f6a8_90bea66de1c231edf33913ecd54406c1_0_0) switched from SCHEDULED to DEPLOYING.
2024-02-19 15:03:11,546 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying KeyedProcess -> Sink: Unnamed (1/1) (attempt #0) with attempt id 1da3547ae8fff4202794575a02f9f6a8_90bea66de1c231edf33913ecd54406c1_0_0 and vertex id 90bea66de1c231edf33913ecd54406c1_0 to localhost:59700-9f4b30 @ localhost (dataPort=59702) with allocation id 8b297cd103e340ade795beb618768c04
2024-02-19 15:03:11,617 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [price-0]
2024-02-19 15:03:11,906 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (1da3547ae8fff4202794575a02f9f6a8_90bea66de1c231edf33913ecd54406c1_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-19 15:03:11,913 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1da3547ae8fff4202794575a02f9f6a8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-19 15:03:11,916 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (1da3547ae8fff4202794575a02f9f6a8_90bea66de1c231edf33913ecd54406c1_0_0) switched from INITIALIZING to RUNNING.
2024-02-19 15:03:11,924 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 0 (#0) @ localhost
2024-02-19 15:03:11,924 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1da3547ae8fff4202794575a02f9f6a8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2024-02-19 15:03:11,924 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: price-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]}
2024-02-19 15:03:34,560 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (1da3547ae8fff4202794575a02f9f6a8_90bea66de1c231edf33913ecd54406c1_0_0) switched from RUNNING to FAILED on localhost:59700-9f4b30 @ localhost (dataPort=59702).
java.lang.ArrayIndexOutOfBoundsException: Index 4 out of bounds for length 4
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:97) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62) ~[?:?]
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
2024-02-19 15:03:34,562 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (e684f68e53cc2501fe399a981490fe4b) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:258) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:249) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:242) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:748) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:725) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:80) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:479) ~[flink-dist-1.17.0.jar:1.17.0]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:309) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:307) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:222) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive(Actor.scala:537) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive$(Actor.scala:535) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.invoke(ActorCell.scala:547) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.run(Mailbox.scala:231) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290) [?:?]
	at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) [?:?]
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) [?:?]
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) [?:?]
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) [?:?]
Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 4 out of bounds for length 4
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:97) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62) ~[?:?]
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
2024-02-19 15:03:34,563 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1da3547ae8fff4202794575a02f9f6a8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2024-02-19 15:03:34,571 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1da3547ae8fff4202794575a02f9f6a8_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2024-02-19 15:03:34,572 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Clearing resource requirements of job e684f68e53cc2501fe399a981490fe4b
2024-02-19 15:03:34,572 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (e684f68e53cc2501fe399a981490fe4b) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:258) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:249) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:242) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:748) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:725) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:80) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:479) ~[flink-dist-1.17.0.jar:1.17.0]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:?]
	at jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:309) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:307) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:222) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive(Actor.scala:537) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive$(Actor.scala:535) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.invoke(ActorCell.scala:547) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.run(Mailbox.scala:231) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290) [?:?]
	at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) [?:?]
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) [?:?]
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) [?:?]
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) [?:?]
Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 4 out of bounds for length 4
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:97) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62) ~[?:?]
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
2024-02-19 15:03:34,572 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job e684f68e53cc2501fe399a981490fe4b.
2024-02-19 15:03:34,573 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job e684f68e53cc2501fe399a981490fe4b reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:83)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:258)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:249)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:242)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:748)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:725)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:80)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:479)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:309)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:307)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:222)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 4 out of bounds for length 4
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:97)
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62)
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83)
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237)
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146)
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
2024-02-19 15:03:34,576 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job e684f68e53cc2501fe399a981490fe4b has been registered for cleanup in the JobResultStore after reaching a terminal state.
2024-02-19 15:03:34,577 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'Run Price Consumer' (e684f68e53cc2501fe399a981490fe4b).
2024-02-19 15:03:34,577 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2024-02-19 15:03:34,577 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Kafka Source.
2024-02-19 15:03:34,578 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:59700-9f4b30 because: Stopping JobMaster for job 'Run Price Consumer' (e684f68e53cc2501fe399a981490fe4b).
2024-02-19 15:03:34,578 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [8b297cd103e340ade795beb618768c04].
2024-02-19 15:03:34,578 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 0e97d5ff2a0642a0362e4fa920c6027b: Stopping JobMaster for job 'Run Price Consumer' (e684f68e53cc2501fe399a981490fe4b).
2024-02-19 15:03:34,579 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_3 for job e684f68e53cc2501fe399a981490fe4b from the resource manager.
2024-02-19 15:03:34,579 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for price-consumer-group-enumerator-admin-client unregistered
2024-02-19 15:03:34,581 ERROR org.apache.kafka.common.utils.Utils                          [] - Failed to close release connections with type org.apache.kafka.common.network.Selector$$Lambda$1750/0x0000000800b39c40
java.lang.NoClassDefFoundError: org/apache/kafka/common/network/Selector$CloseMode
	at org.apache.kafka.common.network.Selector.close(Selector.java:885) ~[blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.common.network.Selector.lambda$null$0(Selector.java:368) ~[blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1015) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.common.utils.Utils.closeAllQuietly(Utils.java:1030) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.common.network.Selector.close(Selector.java:367) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:653) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1005) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1356) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.network.Selector$CloseMode
	at java.net.URLClassLoader.findClass(URLClassLoader.java:476) ~[?:?]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:594) ~[?:?]
	at org.apache.flink.util.FlinkUserCodeClassLoader.loadClassWithoutExceptionHandling(FlinkUserCodeClassLoader.java:67) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.util.ChildFirstClassLoader.loadClassWithoutExceptionHandling(ChildFirstClassLoader.java:74) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.util.FlinkUserCodeClassLoader.loadClass(FlinkUserCodeClassLoader.java:51) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:527) ~[?:?]
	... 9 more
2024-02-19 15:03:34,582 ERROR org.apache.kafka.common.utils.Utils                          [] - Failed to close release connections with type org.apache.kafka.common.network.Selector$$Lambda$1750/0x0000000800b39c40
java.lang.NoClassDefFoundError: org/apache/kafka/common/network/Selector$CloseMode
	at org.apache.kafka.common.network.Selector.close(Selector.java:885) ~[blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.common.network.Selector.lambda$null$0(Selector.java:368) ~[blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1015) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.common.utils.Utils.closeAllQuietly(Utils.java:1030) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.common.network.Selector.close(Selector.java:367) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:653) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1005) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1356) [blob_p-0bae61acaadd2ebb7f6cb393afe2c8ac3d203fa6-e6fa1df966d3945c62247a68c5c4c92f:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-02-19 15:03:34,584 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2024-02-19 15:03:34,584 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-02-19 15:03:34,584 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2024-02-19 15:03:34,584 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Kafka Source closed.
2024-02-19 15:19:47,385 WARN  org.apache.flink.runtime.webmonitor.handlers.JarRunHandler   [] - Configuring the job submission via query parameters is deprecated. Please migrate to submitting a JSON request instead.
2024-02-19 15:19:47,440 INFO  org.apache.flink.client.ClientUtils                          [] - Starting program (detached: true)
2024-02-19 15:19:47,447 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Field Price#data will be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-02-19 15:19:47,462 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Job 5d7acf874158cce0e623d204093f6829 is submitted.
2024-02-19 15:19:47,462 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Submitting Job with JobId=5d7acf874158cce0e623d204093f6829.
2024-02-19 15:19:47,816 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'Run Price Consumer' (5d7acf874158cce0e623d204093f6829).
2024-02-19 15:19:47,817 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'Run Price Consumer' (5d7acf874158cce0e623d204093f6829).
2024-02-19 15:19:47,817 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_4 .
2024-02-19 15:19:47,818 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'Run Price Consumer' (5d7acf874158cce0e623d204093f6829).
2024-02-19 15:19:47,818 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for Run Price Consumer (5d7acf874158cce0e623d204093f6829).
2024-02-19 15:19:47,818 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 1220bfb2ab6d13153b30038503737e53 for job 5d7acf874158cce0e623d204093f6829.
2024-02-19 15:19:47,818 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job Run Price Consumer (5d7acf874158cce0e623d204093f6829).
2024-02-19 15:19:47,818 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2024-02-19 15:19:47,828 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2024-02-19 15:19:47,828 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@3245bf7
2024-02-19 15:19:47,828 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2024-02-19 15:19:47,828 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2024-02-19 15:19:47,829 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-02-19 15:19:47,829 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@742b7bfc for Run Price Consumer (5d7acf874158cce0e623d204093f6829).
2024-02-19 15:19:47,829 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'Run Price Consumer' (5d7acf874158cce0e623d204093f6829) under job master id 00000000000000000000000000000000.
2024-02-19 15:19:47,829 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Kafka Source.
2024-02-19 15:19:47,831 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2024-02-19 15:19:47,831 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (5d7acf874158cce0e623d204093f6829) switched from state CREATED to RUNNING.
2024-02-19 15:19:47,832 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1220bfb2ab6d13153b30038503737e53_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2024-02-19 15:19:47,832 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (1220bfb2ab6d13153b30038503737e53_90bea66de1c231edf33913ecd54406c1_0_0) switched from CREATED to SCHEDULED.
2024-02-19 15:19:47,832 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2024-02-19 15:19:47,832 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2024-02-19 15:19:47,833 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_4 for job 5d7acf874158cce0e623d204093f6829.
2024-02-19 15:19:47,833 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_4 for job 5d7acf874158cce0e623d204093f6829.
2024-02-19 15:19:47,833 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2024-02-19 15:19:47,833 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job 5d7acf874158cce0e623d204093f6829: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-02-19 15:19:47,838 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = price-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-02-19 15:19:47,857 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2024-02-19 15:19:47,857 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2024-02-19 15:19:47,857 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2024-02-19 15:19:47,857 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'client.id.prefix' was supplied but isn't a known config.
2024-02-19 15:19:47,857 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2024-02-19 15:19:47,857 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2024-02-19 15:19:47,857 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2024-02-19 15:19:47,858 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2024-02-19 15:19:47,858 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2024-02-19 15:19:47,858 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1708323587857
2024-02-19 15:19:47,858 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group price-consumer-group without periodic partition discovery.
2024-02-19 15:19:47,905 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1220bfb2ab6d13153b30038503737e53_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2024-02-19 15:19:47,906 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Flat Map (1/1) (attempt #0) with attempt id 1220bfb2ab6d13153b30038503737e53_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:59700-9f4b30 @ localhost (dataPort=59702) with allocation id 6cd6b84b1ab7d209879f0a3c70f025ba
2024-02-19 15:19:47,906 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (1220bfb2ab6d13153b30038503737e53_90bea66de1c231edf33913ecd54406c1_0_0) switched from SCHEDULED to DEPLOYING.
2024-02-19 15:19:47,906 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying KeyedProcess -> Sink: Unnamed (1/1) (attempt #0) with attempt id 1220bfb2ab6d13153b30038503737e53_90bea66de1c231edf33913ecd54406c1_0_0 and vertex id 90bea66de1c231edf33913ecd54406c1_0 to localhost:59700-9f4b30 @ localhost (dataPort=59702) with allocation id 6cd6b84b1ab7d209879f0a3c70f025ba
2024-02-19 15:19:47,983 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [price-0]
2024-02-19 15:19:48,259 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (1220bfb2ab6d13153b30038503737e53_90bea66de1c231edf33913ecd54406c1_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-19 15:19:48,267 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1220bfb2ab6d13153b30038503737e53_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-19 15:19:48,270 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (1220bfb2ab6d13153b30038503737e53_90bea66de1c231edf33913ecd54406c1_0_0) switched from INITIALIZING to RUNNING.
2024-02-19 15:19:48,277 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 0 (#0) @ localhost
2024-02-19 15:19:48,277 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1220bfb2ab6d13153b30038503737e53_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2024-02-19 15:19:48,278 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: price-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]}
2024-02-19 15:20:00,794 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (1220bfb2ab6d13153b30038503737e53_90bea66de1c231edf33913ecd54406c1_0_0) switched from RUNNING to FAILED on localhost:59700-9f4b30 @ localhost (dataPort=59702).
java.lang.ArrayIndexOutOfBoundsException: Index 4 out of bounds for length 4
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:101) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62) ~[?:?]
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
2024-02-19 15:20:00,795 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (5d7acf874158cce0e623d204093f6829) switched from state RUNNING to FAILING.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:258) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:249) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:242) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:748) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:725) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:80) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:479) ~[flink-dist-1.17.0.jar:1.17.0]
	at jdk.internal.reflect.GeneratedMethodAccessor50.invoke(Unknown Source) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:309) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:307) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:222) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive(Actor.scala:537) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive$(Actor.scala:535) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.invoke(ActorCell.scala:547) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.run(Mailbox.scala:231) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290) [?:?]
	at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) [?:?]
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) [?:?]
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) [?:?]
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) [?:?]
Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 4 out of bounds for length 4
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:101) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62) ~[?:?]
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
2024-02-19 15:20:00,796 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1220bfb2ab6d13153b30038503737e53_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2024-02-19 15:20:00,804 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (1220bfb2ab6d13153b30038503737e53_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2024-02-19 15:20:00,805 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Clearing resource requirements of job 5d7acf874158cce0e623d204093f6829
2024-02-19 15:20:00,805 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (5d7acf874158cce0e623d204093f6829) switched from state FAILING to FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:258) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:249) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:242) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:748) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:725) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:80) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:479) ~[flink-dist-1.17.0.jar:1.17.0]
	at jdk.internal.reflect.GeneratedMethodAccessor50.invoke(Unknown Source) ~[?:?]
	at jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:?]
	at java.lang.reflect.Method.invoke(Method.java:566) ~[?:?]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:309) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:307) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:222) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168) ~[flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive(Actor.scala:537) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.Actor.aroundReceive$(Actor.scala:535) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.actor.ActorCell.invoke(ActorCell.scala:547) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.run(Mailbox.scala:231) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243) [flink-rpc-akka_76a26432-448a-43ac-a24d-a520e4208ac8.jar:1.17.0]
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290) [?:?]
	at java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020) [?:?]
	at java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656) [?:?]
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594) [?:?]
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183) [?:?]
Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 4 out of bounds for length 4
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:101) ~[?:?]
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62) ~[?:?]
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.Thread.run(Thread.java:829) ~[?:?]
2024-02-19 15:20:00,805 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 5d7acf874158cce0e623d204093f6829.
2024-02-19 15:20:00,806 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 5d7acf874158cce0e623d204093f6829 reached terminal state FAILED.
org.apache.flink.runtime.JobException: Recovery is suppressed by NoRestartBackoffTimeStrategy
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.handleFailure(ExecutionFailureHandler.java:139)
	at org.apache.flink.runtime.executiongraph.failover.flip1.ExecutionFailureHandler.getFailureHandlingResult(ExecutionFailureHandler.java:83)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.recordTaskFailure(DefaultScheduler.java:258)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.handleTaskFailure(DefaultScheduler.java:249)
	at org.apache.flink.runtime.scheduler.DefaultScheduler.onTaskFailed(DefaultScheduler.java:242)
	at org.apache.flink.runtime.scheduler.SchedulerBase.onTaskExecutionStateUpdate(SchedulerBase.java:748)
	at org.apache.flink.runtime.scheduler.SchedulerBase.updateTaskExecutionState(SchedulerBase.java:725)
	at org.apache.flink.runtime.scheduler.SchedulerNG.updateTaskExecutionState(SchedulerNG.java:80)
	at org.apache.flink.runtime.jobmaster.JobMaster.updateTaskExecutionState(JobMaster.java:479)
	at jdk.internal.reflect.GeneratedMethodAccessor50.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRpcInvocation$1(AkkaRpcActor.java:309)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcInvocation(AkkaRpcActor.java:307)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:222)
	at org.apache.flink.runtime.rpc.akka.FencedAkkaRpcActor.handleRpcMessage(FencedAkkaRpcActor.java:84)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.ArrayIndexOutOfBoundsException: Index 4 out of bounds for length 4
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:101)
	at consumer.PriceConsumer$2.processElement(PriceConsumer.java:62)
	at org.apache.flink.streaming.api.operators.KeyedProcessOperator.processElement(KeyedProcessOperator.java:83)
	at org.apache.flink.streaming.runtime.io.RecordProcessorUtils.lambda$getRecordProcessor$0(RecordProcessorUtils.java:60)
	at org.apache.flink.streaming.runtime.tasks.OneInputStreamTask$StreamTaskNetworkOutput.emitRecord(OneInputStreamTask.java:237)
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.processElement(AbstractStreamTaskNetworkInput.java:146)
	at org.apache.flink.streaming.runtime.io.AbstractStreamTaskNetworkInput.emitNext(AbstractStreamTaskNetworkInput.java:110)
	at org.apache.flink.streaming.runtime.io.StreamOneInputProcessor.processInput(StreamOneInputProcessor.java:65)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.processInput(StreamTask.java:550)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:231)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
2024-02-19 15:20:00,809 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 5d7acf874158cce0e623d204093f6829 has been registered for cleanup in the JobResultStore after reaching a terminal state.
2024-02-19 15:20:00,809 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'Run Price Consumer' (5d7acf874158cce0e623d204093f6829).
2024-02-19 15:20:00,810 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2024-02-19 15:20:00,810 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Kafka Source.
2024-02-19 15:20:00,810 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:59700-9f4b30 because: Stopping JobMaster for job 'Run Price Consumer' (5d7acf874158cce0e623d204093f6829).
2024-02-19 15:20:00,810 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [6cd6b84b1ab7d209879f0a3c70f025ba].
2024-02-19 15:20:00,810 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 0e97d5ff2a0642a0362e4fa920c6027b: Stopping JobMaster for job 'Run Price Consumer' (5d7acf874158cce0e623d204093f6829).
2024-02-19 15:20:00,810 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_4 for job 5d7acf874158cce0e623d204093f6829 from the resource manager.
2024-02-19 15:20:00,811 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for price-consumer-group-enumerator-admin-client unregistered
2024-02-19 15:20:00,812 ERROR org.apache.kafka.common.utils.Utils                          [] - Failed to close release connections with type org.apache.kafka.common.network.Selector$$Lambda$1940/0x0000000800c32440
java.lang.NoClassDefFoundError: org/apache/kafka/common/network/Selector$CloseMode
	at org.apache.kafka.common.network.Selector.close(Selector.java:885) ~[blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.common.network.Selector.lambda$null$0(Selector.java:368) ~[blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1015) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.common.utils.Utils.closeAllQuietly(Utils.java:1030) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.common.network.Selector.close(Selector.java:367) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:653) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1005) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1356) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.network.Selector$CloseMode
	at java.net.URLClassLoader.findClass(URLClassLoader.java:476) ~[?:?]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:594) ~[?:?]
	at org.apache.flink.util.FlinkUserCodeClassLoader.loadClassWithoutExceptionHandling(FlinkUserCodeClassLoader.java:67) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.util.ChildFirstClassLoader.loadClassWithoutExceptionHandling(ChildFirstClassLoader.java:74) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.util.FlinkUserCodeClassLoader.loadClass(FlinkUserCodeClassLoader.java:51) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:527) ~[?:?]
	... 9 more
2024-02-19 15:20:00,813 ERROR org.apache.kafka.common.utils.Utils                          [] - Failed to close release connections with type org.apache.kafka.common.network.Selector$$Lambda$1940/0x0000000800c32440
java.lang.NoClassDefFoundError: org/apache/kafka/common/network/Selector$CloseMode
	at org.apache.kafka.common.network.Selector.close(Selector.java:885) ~[blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.common.network.Selector.lambda$null$0(Selector.java:368) ~[blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1015) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.common.utils.Utils.closeAllQuietly(Utils.java:1030) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.common.network.Selector.close(Selector.java:367) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:653) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1005) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1356) [blob_p-991f3a75524b65941fa666c539d113de4749a553-5aa2689b13809cb2976f9bef1670c6ab:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-02-19 15:20:00,814 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2024-02-19 15:20:00,814 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-02-19 15:20:00,814 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2024-02-19 15:20:00,814 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Kafka Source closed.
2024-02-19 15:24:56,139 WARN  org.apache.flink.runtime.webmonitor.handlers.JarRunHandler   [] - Configuring the job submission via query parameters is deprecated. Please migrate to submitting a JSON request instead.
2024-02-19 15:24:56,194 INFO  org.apache.flink.client.ClientUtils                          [] - Starting program (detached: true)
2024-02-19 15:24:56,201 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Field Price#data will be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-02-19 15:24:56,217 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Job d2dc0087bb6b20b0b722717d5c1e5e46 is submitted.
2024-02-19 15:24:56,217 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Submitting Job with JobId=d2dc0087bb6b20b0b722717d5c1e5e46.
2024-02-19 15:24:56,578 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'Run Price Consumer' (d2dc0087bb6b20b0b722717d5c1e5e46).
2024-02-19 15:24:56,578 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'Run Price Consumer' (d2dc0087bb6b20b0b722717d5c1e5e46).
2024-02-19 15:24:56,579 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_5 .
2024-02-19 15:24:56,579 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'Run Price Consumer' (d2dc0087bb6b20b0b722717d5c1e5e46).
2024-02-19 15:24:56,579 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for Run Price Consumer (d2dc0087bb6b20b0b722717d5c1e5e46).
2024-02-19 15:24:56,580 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 2f7c28b1d7cc211afb4507eff3dbd0c5 for job d2dc0087bb6b20b0b722717d5c1e5e46.
2024-02-19 15:24:56,580 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job Run Price Consumer (d2dc0087bb6b20b0b722717d5c1e5e46).
2024-02-19 15:24:56,580 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2024-02-19 15:24:56,589 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2024-02-19 15:24:56,590 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@29cc8a75
2024-02-19 15:24:56,590 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2024-02-19 15:24:56,590 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2024-02-19 15:24:56,590 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-02-19 15:24:56,590 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@5c1566c9 for Run Price Consumer (d2dc0087bb6b20b0b722717d5c1e5e46).
2024-02-19 15:24:56,590 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'Run Price Consumer' (d2dc0087bb6b20b0b722717d5c1e5e46) under job master id 00000000000000000000000000000000.
2024-02-19 15:24:56,591 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Kafka Source.
2024-02-19 15:24:56,593 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2024-02-19 15:24:56,593 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (d2dc0087bb6b20b0b722717d5c1e5e46) switched from state CREATED to RUNNING.
2024-02-19 15:24:56,593 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2024-02-19 15:24:56,593 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_90bea66de1c231edf33913ecd54406c1_0_0) switched from CREATED to SCHEDULED.
2024-02-19 15:24:56,593 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2024-02-19 15:24:56,594 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2024-02-19 15:24:56,594 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_5 for job d2dc0087bb6b20b0b722717d5c1e5e46.
2024-02-19 15:24:56,594 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_5 for job d2dc0087bb6b20b0b722717d5c1e5e46.
2024-02-19 15:24:56,594 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2024-02-19 15:24:56,594 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job d2dc0087bb6b20b0b722717d5c1e5e46: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-02-19 15:24:56,599 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = price-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-02-19 15:24:56,618 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2024-02-19 15:24:56,618 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2024-02-19 15:24:56,618 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2024-02-19 15:24:56,618 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'client.id.prefix' was supplied but isn't a known config.
2024-02-19 15:24:56,618 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2024-02-19 15:24:56,618 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2024-02-19 15:24:56,618 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2024-02-19 15:24:56,619 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2024-02-19 15:24:56,619 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2024-02-19 15:24:56,619 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1708323896618
2024-02-19 15:24:56,619 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group price-consumer-group without periodic partition discovery.
2024-02-19 15:24:56,670 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2024-02-19 15:24:56,672 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Flat Map (1/1) (attempt #0) with attempt id 2f7c28b1d7cc211afb4507eff3dbd0c5_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:59700-9f4b30 @ localhost (dataPort=59702) with allocation id 0d296314efea5496d2ec973f4330af32
2024-02-19 15:24:56,672 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_90bea66de1c231edf33913ecd54406c1_0_0) switched from SCHEDULED to DEPLOYING.
2024-02-19 15:24:56,672 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying KeyedProcess -> Sink: Unnamed (1/1) (attempt #0) with attempt id 2f7c28b1d7cc211afb4507eff3dbd0c5_90bea66de1c231edf33913ecd54406c1_0_0 and vertex id 90bea66de1c231edf33913ecd54406c1_0 to localhost:59700-9f4b30 @ localhost (dataPort=59702) with allocation id 0d296314efea5496d2ec973f4330af32
2024-02-19 15:24:56,755 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [price-0]
2024-02-19 15:24:57,032 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_90bea66de1c231edf33913ecd54406c1_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-19 15:24:57,040 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-19 15:24:57,043 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_90bea66de1c231edf33913ecd54406c1_0_0) switched from INITIALIZING to RUNNING.
2024-02-19 15:24:57,050 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 0 (#0) @ localhost
2024-02-19 15:24:57,050 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2024-02-19 15:24:57,050 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: price-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]}
2024-02-19 15:29:56,758 INFO  org.apache.kafka.clients.NetworkClient                       [] - [AdminClient clientId=price-consumer-group-enumerator-admin-client] Node -1 disconnected.
2024-02-19 15:34:14,057 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (d2dc0087bb6b20b0b722717d5c1e5e46) switched from state RUNNING to CANCELLING.
2024-02-19 15:34:14,061 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2024-02-19 15:34:14,062 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_90bea66de1c231edf33913ecd54406c1_0_0) switched from RUNNING to CANCELING.
2024-02-19 15:34:14,078 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_90bea66de1c231edf33913ecd54406c1_0_0) switched from CANCELING to CANCELED.
2024-02-19 15:34:14,083 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (2f7c28b1d7cc211afb4507eff3dbd0c5_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2024-02-19 15:34:14,084 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (d2dc0087bb6b20b0b722717d5c1e5e46) switched from state CANCELLING to CANCELED.
2024-02-19 15:34:14,084 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Clearing resource requirements of job d2dc0087bb6b20b0b722717d5c1e5e46
2024-02-19 15:34:14,084 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job d2dc0087bb6b20b0b722717d5c1e5e46.
2024-02-19 15:34:14,085 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job d2dc0087bb6b20b0b722717d5c1e5e46 reached terminal state CANCELED.
2024-02-19 15:34:14,088 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job d2dc0087bb6b20b0b722717d5c1e5e46 has been registered for cleanup in the JobResultStore after reaching a terminal state.
2024-02-19 15:34:14,088 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'Run Price Consumer' (d2dc0087bb6b20b0b722717d5c1e5e46).
2024-02-19 15:34:14,089 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2024-02-19 15:34:14,089 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Kafka Source.
2024-02-19 15:34:14,089 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:59700-9f4b30 because: Stopping JobMaster for job 'Run Price Consumer' (d2dc0087bb6b20b0b722717d5c1e5e46).
2024-02-19 15:34:14,089 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [0d296314efea5496d2ec973f4330af32].
2024-02-19 15:34:14,089 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 0e97d5ff2a0642a0362e4fa920c6027b: Stopping JobMaster for job 'Run Price Consumer' (d2dc0087bb6b20b0b722717d5c1e5e46).
2024-02-19 15:34:14,091 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for price-consumer-group-enumerator-admin-client unregistered
2024-02-19 15:34:14,091 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_5 for job d2dc0087bb6b20b0b722717d5c1e5e46 from the resource manager.
2024-02-19 15:34:14,095 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2024-02-19 15:34:14,095 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-02-19 15:34:14,095 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2024-02-19 15:34:14,095 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Kafka Source closed.
2024-02-19 17:02:56,693 ERROR org.apache.flink.runtime.rest.handler.job.JobDetailsHandler  [] - Exception occurred in REST handler: Job d2dc0087bb6b20b0b722717d5c1e5e46 not found
2024-02-19 17:02:56,712 ERROR org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler [] - Exception occurred in REST handler: Job d2dc0087bb6b20b0b722717d5c1e5e46 not found
2024-02-19 17:08:34,964 ERROR org.apache.flink.runtime.rest.handler.job.JobDetailsHandler  [] - Exception occurred in REST handler: Job d2dc0087bb6b20b0b722717d5c1e5e46 not found
2024-02-19 17:08:34,976 ERROR org.apache.flink.runtime.rest.handler.job.JobExceptionsHandler [] - Exception occurred in REST handler: Job d2dc0087bb6b20b0b722717d5c1e5e46 not found
2024-02-19 17:09:17,939 WARN  org.apache.flink.runtime.webmonitor.handlers.JarRunHandler   [] - Configuring the job submission via query parameters is deprecated. Please migrate to submitting a JSON request instead.
2024-02-19 17:09:17,975 INFO  org.apache.flink.client.ClientUtils                          [] - Starting program (detached: true)
2024-02-19 17:09:17,980 INFO  org.apache.flink.api.java.typeutils.TypeExtractor            [] - Field Price#data will be processed as GenericType. Please read the Flink documentation on "Data Types & Serialization" for details of the effect on performance and schema evolution.
2024-02-19 17:09:17,991 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Job 7a9bd49ed20ef2e0e8cacb1100d8e6f9 is submitted.
2024-02-19 17:09:17,992 INFO  org.apache.flink.client.deployment.application.executors.EmbeddedExecutor [] - Submitting Job with JobId=7a9bd49ed20ef2e0e8cacb1100d8e6f9.
2024-02-19 17:09:18,344 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Received JobGraph submission 'Run Price Consumer' (7a9bd49ed20ef2e0e8cacb1100d8e6f9).
2024-02-19 17:09:18,344 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Submitting job 'Run Price Consumer' (7a9bd49ed20ef2e0e8cacb1100d8e6f9).
2024-02-19 17:09:18,345 INFO  org.apache.flink.runtime.rpc.akka.AkkaRpcService             [] - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_6 .
2024-02-19 17:09:18,345 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Initializing job 'Run Price Consumer' (7a9bd49ed20ef2e0e8cacb1100d8e6f9).
2024-02-19 17:09:18,346 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using restart back off time strategy NoRestartBackoffTimeStrategy for Run Price Consumer (7a9bd49ed20ef2e0e8cacb1100d8e6f9).
2024-02-19 17:09:18,346 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Created execution graph 6d19a997ac3aa16224e41cbfc7a50557 for job 7a9bd49ed20ef2e0e8cacb1100d8e6f9.
2024-02-19 17:09:18,346 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Running initialization on master for job Run Price Consumer (7a9bd49ed20ef2e0e8cacb1100d8e6f9).
2024-02-19 17:09:18,346 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Successfully ran initialization on master in 0 ms.
2024-02-19 17:09:18,359 INFO  org.apache.flink.runtime.scheduler.adapter.DefaultExecutionTopology [] - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
2024-02-19 17:09:18,359 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - No state backend has been configured, using default (HashMap) org.apache.flink.runtime.state.hashmap.HashMapStateBackend@2d28aac4
2024-02-19 17:09:18,359 INFO  org.apache.flink.runtime.state.StateBackendLoader            [] - State backend loader loads the state backend as HashMapStateBackend
2024-02-19 17:09:18,359 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Checkpoint storage is set to 'jobmanager'
2024-02-19 17:09:18,360 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - No checkpoint found during restore.
2024-02-19 17:09:18,360 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@46b66795 for Run Price Consumer (7a9bd49ed20ef2e0e8cacb1100d8e6f9).
2024-02-19 17:09:18,360 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting execution of job 'Run Price Consumer' (7a9bd49ed20ef2e0e8cacb1100d8e6f9) under job master id 00000000000000000000000000000000.
2024-02-19 17:09:18,361 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Starting split enumerator for source Source: Kafka Source.
2024-02-19 17:09:18,363 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
2024-02-19 17:09:18,363 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (7a9bd49ed20ef2e0e8cacb1100d8e6f9) switched from state CREATED to RUNNING.
2024-02-19 17:09:18,363 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (6d19a997ac3aa16224e41cbfc7a50557_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
2024-02-19 17:09:18,363 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (6d19a997ac3aa16224e41cbfc7a50557_90bea66de1c231edf33913ecd54406c1_0_0) switched from CREATED to SCHEDULED.
2024-02-19 17:09:18,363 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Connecting to ResourceManager akka.tcp://flink@localhost:6123/user/rpc/resourcemanager_*(00000000000000000000000000000000)
2024-02-19 17:09:18,364 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Resolved ResourceManager address, beginning registration
2024-02-19 17:09:18,364 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registering job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_6 for job 7a9bd49ed20ef2e0e8cacb1100d8e6f9.
2024-02-19 17:09:18,364 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Registered job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_6 for job 7a9bd49ed20ef2e0e8cacb1100d8e6f9.
2024-02-19 17:09:18,364 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - JobManager successfully registered at ResourceManager, leader id: 00000000000000000000000000000000.
2024-02-19 17:09:18,364 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Received resource requirements from job 7a9bd49ed20ef2e0e8cacb1100d8e6f9: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
2024-02-19 17:09:18,369 INFO  org.apache.kafka.clients.admin.AdminClientConfig             [] - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = price-consumer-group-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

2024-02-19 17:09:18,388 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'key.deserializer' was supplied but isn't a known config.
2024-02-19 17:09:18,388 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'value.deserializer' was supplied but isn't a known config.
2024-02-19 17:09:18,388 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'enable.auto.commit' was supplied but isn't a known config.
2024-02-19 17:09:18,388 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'client.id.prefix' was supplied but isn't a known config.
2024-02-19 17:09:18,388 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'group.id' was supplied but isn't a known config.
2024-02-19 17:09:18,388 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
2024-02-19 17:09:18,388 WARN  org.apache.kafka.clients.admin.AdminClientConfig             [] - The configuration 'auto.offset.reset' was supplied but isn't a known config.
2024-02-19 17:09:18,389 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka version: 3.2.3
2024-02-19 17:09:18,389 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka commitId: 50029d3ed8ba576f
2024-02-19 17:09:18,389 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - Kafka startTimeMs: 1708330158388
2024-02-19 17:09:18,389 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Starting the KafkaSourceEnumerator for consumer group price-consumer-group without periodic partition discovery.
2024-02-19 17:09:18,434 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (6d19a997ac3aa16224e41cbfc7a50557_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
2024-02-19 17:09:18,435 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying Source: Kafka Source -> Flat Map (1/1) (attempt #0) with attempt id 6d19a997ac3aa16224e41cbfc7a50557_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to localhost:59700-9f4b30 @ localhost (dataPort=59702) with allocation id 1745dfdf3573c9d447f03e1c331adbcb
2024-02-19 17:09:18,435 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (6d19a997ac3aa16224e41cbfc7a50557_90bea66de1c231edf33913ecd54406c1_0_0) switched from SCHEDULED to DEPLOYING.
2024-02-19 17:09:18,435 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Deploying KeyedProcess -> Sink: Unnamed (1/1) (attempt #0) with attempt id 6d19a997ac3aa16224e41cbfc7a50557_90bea66de1c231edf33913ecd54406c1_0_0 and vertex id 90bea66de1c231edf33913ecd54406c1_0 to localhost:59700-9f4b30 @ localhost (dataPort=59702) with allocation id 1745dfdf3573c9d447f03e1c331adbcb
2024-02-19 17:09:18,510 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Discovered new partitions: [price-0]
2024-02-19 17:09:18,786 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (6d19a997ac3aa16224e41cbfc7a50557_90bea66de1c231edf33913ecd54406c1_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-19 17:09:18,793 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (6d19a997ac3aa16224e41cbfc7a50557_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
2024-02-19 17:09:18,796 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (6d19a997ac3aa16224e41cbfc7a50557_90bea66de1c231edf33913ecd54406c1_0_0) switched from INITIALIZING to RUNNING.
2024-02-19 17:09:18,806 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source Source: Kafka Source registering reader for parallel task 0 (#0) @ localhost
2024-02-19 17:09:18,806 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (6d19a997ac3aa16224e41cbfc7a50557_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
2024-02-19 17:09:18,806 INFO  org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator [] - Assigning splits to readers {0=[[Partition: price-0, StartingOffset: -1, StoppingOffset: -9223372036854775808]]}
2024-02-19 17:11:38,418 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (7a9bd49ed20ef2e0e8cacb1100d8e6f9) switched from state RUNNING to CANCELLING.
2024-02-19 17:11:38,418 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (6d19a997ac3aa16224e41cbfc7a50557_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
2024-02-19 17:11:38,419 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (6d19a997ac3aa16224e41cbfc7a50557_90bea66de1c231edf33913ecd54406c1_0_0) switched from RUNNING to CANCELING.
2024-02-19 17:11:38,446 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - KeyedProcess -> Sink: Unnamed (1/1) (6d19a997ac3aa16224e41cbfc7a50557_90bea66de1c231edf33913ecd54406c1_0_0) switched from CANCELING to CANCELED.
2024-02-19 17:11:38,450 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Source: Kafka Source -> Flat Map (1/1) (6d19a997ac3aa16224e41cbfc7a50557_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
2024-02-19 17:11:38,451 INFO  org.apache.flink.runtime.executiongraph.ExecutionGraph       [] - Job Run Price Consumer (7a9bd49ed20ef2e0e8cacb1100d8e6f9) switched from state CANCELLING to CANCELED.
2024-02-19 17:11:38,451 INFO  org.apache.flink.runtime.resourcemanager.slotmanager.DeclarativeSlotManager [] - Clearing resource requirements of job 7a9bd49ed20ef2e0e8cacb1100d8e6f9
2024-02-19 17:11:38,451 INFO  org.apache.flink.runtime.checkpoint.CheckpointCoordinator    [] - Stopping checkpoint coordinator for job 7a9bd49ed20ef2e0e8cacb1100d8e6f9.
2024-02-19 17:11:38,452 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 7a9bd49ed20ef2e0e8cacb1100d8e6f9 reached terminal state CANCELED.
2024-02-19 17:11:38,455 INFO  org.apache.flink.runtime.dispatcher.StandaloneDispatcher     [] - Job 7a9bd49ed20ef2e0e8cacb1100d8e6f9 has been registered for cleanup in the JobResultStore after reaching a terminal state.
2024-02-19 17:11:38,455 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Stopping the JobMaster for job 'Run Price Consumer' (7a9bd49ed20ef2e0e8cacb1100d8e6f9).
2024-02-19 17:11:38,456 INFO  org.apache.flink.runtime.checkpoint.StandaloneCompletedCheckpointStore [] - Shutting down
2024-02-19 17:11:38,456 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Closing SourceCoordinator for source Source: Kafka Source.
2024-02-19 17:11:38,456 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Disconnect TaskExecutor localhost:59700-9f4b30 because: Stopping JobMaster for job 'Run Price Consumer' (7a9bd49ed20ef2e0e8cacb1100d8e6f9).
2024-02-19 17:11:38,456 INFO  org.apache.flink.runtime.jobmaster.slotpool.DefaultDeclarativeSlotPool [] - Releasing slot [1745dfdf3573c9d447f03e1c331adbcb].
2024-02-19 17:11:38,458 INFO  org.apache.flink.runtime.jobmaster.JobMaster                 [] - Close ResourceManager connection 0e97d5ff2a0642a0362e4fa920c6027b: Stopping JobMaster for job 'Run Price Consumer' (7a9bd49ed20ef2e0e8cacb1100d8e6f9).
2024-02-19 17:11:38,458 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Disconnect job manager 00000000000000000000000000000000@akka.tcp://flink@localhost:6123/user/rpc/jobmanager_6 for job 7a9bd49ed20ef2e0e8cacb1100d8e6f9 from the resource manager.
2024-02-19 17:11:38,458 INFO  org.apache.kafka.common.utils.AppInfoParser                  [] - App info kafka.admin.client for price-consumer-group-enumerator-admin-client unregistered
2024-02-19 17:11:38,462 ERROR org.apache.kafka.common.utils.Utils                          [] - Failed to close release connections with type org.apache.kafka.common.network.Selector$$Lambda$2303/0x0000000800deac40
java.lang.NoClassDefFoundError: org/apache/kafka/common/network/Selector$CloseMode
	at org.apache.kafka.common.network.Selector.close(Selector.java:885) ~[blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.common.network.Selector.lambda$null$0(Selector.java:368) ~[blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1015) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.common.utils.Utils.closeAllQuietly(Utils.java:1030) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.common.network.Selector.close(Selector.java:367) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:653) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1005) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1356) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
Caused by: java.lang.ClassNotFoundException: org.apache.kafka.common.network.Selector$CloseMode
	at java.net.URLClassLoader.findClass(URLClassLoader.java:476) ~[?:?]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:594) ~[?:?]
	at org.apache.flink.util.FlinkUserCodeClassLoader.loadClassWithoutExceptionHandling(FlinkUserCodeClassLoader.java:67) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.util.ChildFirstClassLoader.loadClassWithoutExceptionHandling(ChildFirstClassLoader.java:74) ~[flink-dist-1.17.0.jar:1.17.0]
	at org.apache.flink.util.FlinkUserCodeClassLoader.loadClass(FlinkUserCodeClassLoader.java:51) ~[flink-dist-1.17.0.jar:1.17.0]
	at java.lang.ClassLoader.loadClass(ClassLoader.java:527) ~[?:?]
	... 9 more
2024-02-19 17:11:38,462 ERROR org.apache.kafka.common.utils.Utils                          [] - Failed to close release connections with type org.apache.kafka.common.network.Selector$$Lambda$2303/0x0000000800deac40
java.lang.NoClassDefFoundError: org/apache/kafka/common/network/Selector$CloseMode
	at org.apache.kafka.common.network.Selector.close(Selector.java:885) ~[blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.common.network.Selector.lambda$null$0(Selector.java:368) ~[blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1015) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.common.utils.Utils.closeAllQuietly(Utils.java:1030) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.common.network.Selector.close(Selector.java:367) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.clients.NetworkClient.close(NetworkClient.java:653) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.common.utils.Utils.closeQuietly(Utils.java:1005) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at org.apache.kafka.clients.admin.KafkaAdminClient$AdminClientRunnable.run(KafkaAdminClient.java:1356) [blob_p-dec439e44ebe2d8aa27e3a1b6be45df8f2d4e560-1227174fb1bd27f793850ff106d93868:?]
	at java.lang.Thread.run(Thread.java:829) [?:?]
2024-02-19 17:11:38,465 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics scheduler closed
2024-02-19 17:11:38,465 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Closing reporter org.apache.kafka.common.metrics.JmxReporter
2024-02-19 17:11:38,465 INFO  org.apache.kafka.common.metrics.Metrics                      [] - Metrics reporters closed
2024-02-19 17:11:38,465 INFO  org.apache.flink.runtime.source.coordinator.SourceCoordinator [] - Source coordinator for source Source: Kafka Source closed.
2024-02-19 17:13:08,433 INFO  org.apache.flink.runtime.resourcemanager.StandaloneResourceManager [] - Closing TaskExecutor connection localhost:59700-9f4b30 because: The TaskExecutor is shutting down.
2024-02-19 17:13:08,790 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - RECEIVED SIGNAL 15: SIGTERM. Shutting down as requested.
2024-02-19 17:13:08,792 INFO  org.apache.flink.runtime.entrypoint.ClusterEntrypoint        [] - Shutting StandaloneSessionClusterEntrypoint down with application status UNKNOWN. Diagnostics Cluster entrypoint has been closed externally..
2024-02-19 17:13:08,792 INFO  org.apache.flink.runtime.blob.BlobServer                     [] - Stopped BLOB server at 127.0.0.1:59696
